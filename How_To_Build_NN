##This file shows the basic pipeline for building a neural network in with pytorch


from torch import nn
import torch.nn.funtional as F ##contains sigmoid. relu and other methods

class myNetwork(nn.Module）：
    def __init__(self):
        super().__init__()//super用来继承父类里init函数下所有变量和方法
        self.layer1 = nn.Linear(20,64)###nn.conv1d or nn.conv2d各种类型的隐藏层， 参数1表示输入有多少特征（列），参数2表示本层有有多少个神经元
        self.layer2 = nn.....(64,64)
        ....
        
        self.relu = nn.ReLU()###初始化， 使用F的时候不需要初始化
        self.sigmoid = nn.Sigmoid()
    ###通过forward函数来将那些层的结构关联在一起组成一个网络    
    def forward(self, input):
        x = F.relu(self.layer1(input))
        x = F.relu(self.layer2(x))
        x = F.sigmoid(x)
        return x
lr = 0.00001
def getModel():
    model = myNetwork()
    opt = torch.optim.Adam(model.parameters(), lr = lr) ##.parametes returns trainable parameters
    return model, opt
    
loss_fn = nn.BCELoss()   
model, opt = getModel()
batch_size = 64
num_of_batches = len(data)//batch_size ##//整除
num_of_epochs = 1000
for epoch in range(num_of_epochs):
    for i in range(num_of_batches):
        X...
        Y...
        y_pred = model(x)
        loss = loss_fn(y_pred - y)
        opt.zero_grad()
        loss.backward()
        opt.step()
    with torch.no_grad():
        print('epoch: ', epoch, 'loss: ', loss_fn(model(X), Y).data.item()) ##loss returns a torch tensor, need to retreive value from it



###following text shows how to load data
import torch.utils.data as data
import glob
class ModelNetDataset(data.Dataset):##需要从data.Dataset里继承
    def __init__(self, 
                 root, 
                 data_argumentation=True):
       ...
       self.root = root
       self.data_argumentation = data_argumentation
       
    def __getitem__(self, index):###返回切片方法[0]（索引），类似于c++的重载运算符
        return self.root[index]
    
    def __len__(self):
        return len(self.root)

all_path = glob.glob(r'somewhere/somewhere/somewhere/*.txt')
cloud_data = ModelNetDataset(all_path)
dataset = torch.utils.data.DataLoader(cloud_data, batch_size = 10, shuffle = True)


####Created by Mr.KnowHow
        
    
