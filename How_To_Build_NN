##This file shows the basic pipeline for building a neural network in with pytorch


from torch import nn
import torch.nn.funtional as F ##contains sigmoid. relu and other methods

class myNetwork(nn.Module）：
    def __init__(self):
        super().__init__()//super用来继承父类里init函数下所有变量和方法
        self.layer1 = nn.Linear(20,64)###nn.conv1d or nn.conv2d各种类型的隐藏层， 参数1表示输入有多少特征（列），参数2表示本层有有多少个神经元
        self.layer2 = nn.....(64,64)
        ....
        
        self.relu = nn.ReLU()###初始化， 使用F的时候不需要初始化
        self.sigmoid = nn.Sigmoid()
    ###通过forward函数来将那些层的结构关联在一起组成一个网络    
    def forward(self, input):
        x = F.relu(self.layer1(input))
        x = F.relu(self.layer2(x))
        x = F.sigmoid(x)
        return x
lr = 0.00001
def getModel():
    model = myNetwork()
    opt = torch.optim.Adam(model.parameters(), lr = lr) ##.parametes returns trainable parameters
    return model, opt
    
loss_fn = nn.BCELoss()   
model, opt = getModel()
batch_size = 64
num_of_batches = len(data)//batch_size ##//整除
num_of_epochs = 1000
for epoch in range(num_of_epochs):
    for i in range(num_of_batches):
        X...
        Y...
        y_pred = model(x)
        loss = loss_fn(y_pred - y)
        opt.zero_grad()
        loss.backward()
        opt.step()
    with torch.no_grad():
        print('epoch: ', epoch, 'loss: ', loss_fn(model(X), Y).data.item()) ##loss returns a torch tensor, need to retreive value from it



####Created by Mr.KnowHow
        
    
